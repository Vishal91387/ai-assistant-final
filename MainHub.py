import streamlit as st
from PIL import Image
import pytesseract
from deep_translator import GoogleTranslator
import os
import requests
import yfinance as yf

# Your internal modules
from llm_loader import load_llama
from rag_chat import ask_question_from_docs
from ingest_docs import ingest_uploaded_docs
from utils import summarize_answer
from agent_chat import ask_agent


# Load LLaMA model once
llm = load_llama()

st.set_page_config(page_title="ğŸ§  AI Toolbox", layout="wide")
st.title("ğŸ§  My Local AI Toolbox")

st.markdown("""
### ğŸ‘‹ Welcome to Your AI Toolbox

This is your unified interface to access all your local AI tools. Use the tabs below to:

- **ğŸ“„ RAGdoc** â€” Ask questions from your uploaded documents or from live web sources
- **ğŸ“· OCR** â€” Extract and translate text from images in multiple languages
- **ğŸ“ˆ Real-Time AI Watch** â€” Track news and stock prices using live APIs

Select a tab to get started ğŸ‘‡
""")
st.markdown("---")

tabs = st.tabs(["ğŸ“„ RAGdoc", "ğŸ“· OCR", "ğŸ“ˆ Real-Time AI Watch"])

# ---------------------
# ğŸ“„ Tab 1: RAGdoc
# ---------------------
with tabs[0]:
    st.header("ğŸ“„ Ask Questions from Your Documents or the Web")

    mode = st.radio("Choose your data source:", ["ğŸ“„ My Documents", "ğŸŒ Web Sources"], horizontal=True)

    if mode == "ğŸ“„ My Documents":
        st.sidebar.title("ğŸ“„ Upload & Ingest Docs")
        uploaded_files = st.sidebar.file_uploader(
            "Choose files (.txt, .pdf, .docx)", type=["txt", "pdf", "docx"], accept_multiple_files=True
        )

        if uploaded_files:
            filepaths = []
            for file in uploaded_files:
                path = os.path.join("docs", file.name)
                with open(path, "wb") as f:
                    f.write(file.getbuffer())
                filepaths.append(path)
            ingest_uploaded_docs(filepaths)
            st.sidebar.success("Documents uploaded and processed!")

        question = st.text_input("Ask a question about your documents:")
        if question:
            answer = ask_question_from_docs(question)
            st.markdown("### ğŸ§  Answer")
            st.write(answer)

            # TL;DR Summary
            summary = summarize_answer(answer)
            if summary and any(summary):
                st.markdown("### ğŸ” TL;DR Summary")
                st.markdown("<ul style='padding-left: 20px; font-size: 15px;'>", unsafe_allow_html=True)
                for point in summary:
                    st.markdown(f"<li>{point.strip()}</li>", unsafe_allow_html=True)
                st.markdown("</ul>", unsafe_allow_html=True)
            else:
                st.info("No summary available.")

    elif mode == "ğŸŒ Web Sources":
        question = st.text_input("Ask a web-connected question:")
        if question:
            response = ask_agent(question)
            st.markdown("### ğŸŒ Web Response")
            st.write(response)
# ---------------------
# ğŸ“· Tab 2: OCR
# ---------------------
with tabs[1]:
    st.header("ğŸ“· OCR Image/Text Extraction")

    tessdata_dir = "./tessdata"
    lang = st.selectbox("Select OCR Language", ["eng", "spa", "fra", "deu", "ara"])
    tesseract_config = f"--tessdata-dir {tessdata_dir} -l {lang}"

    uploaded_file = st.file_uploader("Upload an image (PNG, JPG, JPEG)", type=["png", "jpg", "jpeg"])
    
    if uploaded_file:
        image = Image.open(uploaded_file)
        st.image(image, caption="Uploaded Image", use_column_width=True)

        extracted_text = pytesseract.image_to_string(image, config=tesseract_config)
        translated_text = GoogleTranslator(source='auto', target='en').translate(extracted_text)

        st.subheader("ğŸ“ Extracted Text")
        st.text_area("Original Text", extracted_text, height=200)
        
                # --- Download buttons ---
        st.download_button(
            "â¬‡ï¸ Download Original Text",
            data=extracted_text,
            file_name="ocr_original.txt",
            mime="text/plain"
        )

        st.subheader("ğŸŒ Translated to English")
        st.text_area("Translated Text", translated_text, height=200)


        st.download_button(
            "â¬‡ï¸ Download Translated Text",
            data=translated_text,
            file_name="ocr_translated.txt",
            mime="text/plain"
        )

# ---------------------
# ğŸ“ˆ Tab 3: Real-Time AI Watch
# ---------------------
with tabs[2]:
    st.header("ğŸ“ˆ Real-Time News and Stock Tracking")

    tab1, tab2 = st.tabs(["ğŸ“° News", "ğŸ“Š Stock Price"])

    with tab1:
        topic = st.text_input("Enter a news topic (e.g., NATO, Elections, AI)")
        if topic:
            st.info(f"Fetching news for: {topic}")
            api_key = "18f6428e440f51409c62889f5bfeed0a"  # Replace with your actual Mediastack key
            url = "http://api.mediastack.com/v1/news"
            params = {
                "access_key": api_key,
                "keywords": topic,
                "languages": "en",
                "limit": 5,
                "sort": "published_desc"
            }
            response = requests.get(url, params=params)
            news_list = response.json().get("data", [])

            if news_list:
                for article in news_list:
                    st.markdown(f"**{article['title']}**\n\n{article['description']}\n\n[Read more]({article['url']})")
            else:
                st.warning("No news found.")

    with tab2:
        symbol = st.text_input("Enter stock symbol (e.g., AAPL, TSLA, GOOGL)")
        if symbol:
            stock = yf.Ticker(symbol)
            hist = stock.history(period="1d")
            if not hist.empty:
                latest = hist.tail(1)
                st.dataframe(latest)
            else:
                st.warning("No data found for this symbol.")
